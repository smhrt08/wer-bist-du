<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>wer bist du</title>
  <style>
    body { 
      display: flex; 
      flex-direction: column; 
      align-items: center; 
      font-family: sans-serif; 
      margin: 0;
      padding: 20px;
    }
    video { 
      border: 2px solid #333; 
      border-radius: 12px; 
      margin-top: 20px;
      max-width: 100%;
      height: auto;
    }
    #status {
      margin-top: 10px;
      padding: 10px;
      border-radius: 5px;
      background-color: #f0f0f0;
      max-width: 600px;
      text-align: center;
    }
    #debug {
      margin-top: 10px;
      padding: 10px;
      border-radius: 5px;
      background-color: #e8f4f8;
      font-family: monospace;
      font-size: 12px;
      max-width: 600px;
      word-break: break-all;
      max-height: 200px;
      overflow-y: auto;
    }
    button {
      margin: 10px;
      padding: 10px 20px;
      font-size: 16px;
      border: none;
      border-radius: 5px;
      background-color: #007bff;
      color: white;
      cursor: pointer;
    }
    button:hover {
      background-color: #0056b3;
    }
    button:disabled {
      background-color: #ccc;
      cursor: not-allowed;
    }
    .toast {
      visibility: hidden;
      min-width: 300px;
      color: white;
      text-align: center;
      border-radius: 8px;
      padding: 16px;
      position: fixed;
      bottom: 30px;
      left: 50%;
      transform: translateX(-50%);
      z-index: 1;
      transition: visibility 0.5s, opacity 0.5s;
      opacity: 0;
    }
    .toast.show {
      visibility: visible;
      opacity: 1;
    }
    #faceToast {
      background-color: #f44336;
    }
    #lowLightToast {
      background-color: #ffa500;
    }
  </style>
</head>
<body>
  <h1>wer bist du</h1>
  <div id="status">Initializing...</div>
  <div id="debug"></div>
  <button id="startBtn" disabled>Start Camera</button>
  <video id="video" width="640" height="480" autoplay muted playsinline></video>
  <div id="faceToast" class="toast">⚠️ Another person detected in the background!</div>
  <div id="lowLightToast" class="toast">⚠️ Low lighting detected!</div>

  <!-- Face API CDN -->
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.13/dist/face-api.min.js"></script>

  <script>
    const video = document.getElementById('video');
    const startBtn = document.getElementById('startBtn');
    const status = document.getElementById('status');
    const debug = document.getElementById('debug');
    const faceToast = document.getElementById('faceToast');
    const lowLightToast = document.getElementById('lowLightToast');
    let detectionInterval;
    let nativeFaceDetector = null;
    let lastFrame = null;

    // Debug logging
    function addDebug(msg) {
      const timestamp = new Date().toLocaleTimeString();
      debug.innerHTML += `[${timestamp}] ${msg}<br>`;
      debug.scrollTop = debug.scrollHeight;
      console.log(msg);
    }

    // Update status
    function updateStatus(msg) {
      status.textContent = msg;
      addDebug(`STATUS: ${msg}`);
    }

    // Check browser support
    function checkBrowserSupport() {
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        addDebug('ERROR: Camera API not supported');
        return false;
      }
      addDebug('✓ Camera API supported');
      return true;
    }

    // Load face-api models
    async function loadModels() {
      updateStatus('Loading face detection models...');
      try {
        const modelPath = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.13/model/';
        const loadPromise = Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri(modelPath),
          faceapi.nets.faceLandmark68Net.loadFromUri(modelPath),
          faceapi.nets.faceRecognitionNet.loadFromUri(modelPath)
        ]);
        const timeoutPromise = new Promise((_, reject) => setTimeout(() => reject(new Error('Model loading timeout')), 15000));
        await Promise.race([loadPromise, timeoutPromise]);
        addDebug('✓ Models loaded');
        return true;
      } catch (err) {
        addDebug(`Model load failed: ${err.message}`);
        if ('FaceDetector' in window) {
          addDebug('Using native FaceDetector fallback');
          return 'native';
        }
        addDebug('Using motion detection fallback');
        return 'motion';
      }
    }

    async function initNativeFaceDetection() {
      try {
        nativeFaceDetector = new FaceDetector({ maxDetectedFaces: 10, fastMode: false });
        return true;
      } catch (err) {
        addDebug(`Native detector failed: ${err.message}`);
        return false;
      }
    }

    // Low-light detection
    function isLowLight(video, threshold = 50) {
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const frame = ctx.getImageData(0, 0, canvas.width, canvas.height);
      let total = 0;
      for (let i = 0; i < frame.data.length; i += 4) {
        const brightness = 0.299*frame.data[i] + 0.587*frame.data[i+1] + 0.114*frame.data[i+2];
        total += brightness;
      }
      const avg = total / (canvas.width * canvas.height);
      return avg < threshold;
    }

    function showToast(toast) {
      toast.className = "toast show";
      setTimeout(() => { toast.className = toast.className.replace("show", ""); }, 3000);
    }

    // Motion detection fallback
    function detectMotion(video) {
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0);
      const currentFrame = ctx.getImageData(0, 0, canvas.width, canvas.height);
      let hasMotion = false;
      if (lastFrame) {
        let diff = 0;
        for (let i = 0; i < currentFrame.data.length; i += 4) {
          const r = Math.abs(currentFrame.data[i] - lastFrame.data[i]);
          const g = Math.abs(currentFrame.data[i+1] - lastFrame.data[i+1]);
          const b = Math.abs(currentFrame.data[i+2] - lastFrame.data[i+2]);
          diff += (r+g+b)/3;
        }
        const avgDiff = diff / (canvas.width * canvas.height);
        hasMotion = avgDiff > 10;
      }
      lastFrame = currentFrame;
      return hasMotion;
    }

    // Run detection
    async function runDetection() {
      if (video.videoWidth === 0 || video.videoHeight === 0) return;
      let faceCount = 0;

      if (typeof faceapi !== 'undefined' && faceapi.nets.tinyFaceDetector.isLoaded) {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
        faceCount = detections.length;
        addDebug(`Face-api detected ${faceCount} faces`);
      } else if (nativeFaceDetector) {
        const faces = await nativeFaceDetector.detect(video);
        faceCount = faces.length;
        addDebug(`Native detector found ${faceCount} faces`);
      } else {
        const hasMotion = detectMotion(video);
        faceCount = hasMotion ? 2 : 1;
        if (hasMotion) addDebug('Motion detected - simulating multiple people');
      }

      if (faceCount > 1) showToast(faceToast);
      if (isLowLight(video)) showToast(lowLightToast);
    }

    // Start video
    async function startVideo() {
      updateStatus('Requesting camera access...');
      startBtn.disabled = true;
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 }, audio: false });
        video.srcObject = stream;
        updateStatus('Camera connected. Starting detection...');
      } catch (err) {
        addDebug(`Camera error: ${err.message}`);
        updateStatus('Camera access failed: ' + err.message);
        startBtn.disabled = false;
      }
    }

    startBtn.addEventListener('click', startVideo);
    video.addEventListener('play', () => {
      if (detectionInterval) clearInterval(detectionInterval);
      detectionInterval = setInterval(runDetection, 1000);
      updateStatus('Video started. Detection active.');
    });

    window.addEventListener('beforeunload', () => {
      if (detectionInterval) clearInterval(detectionInterval);
      if (video.srcObject) video.srcObject.getTracks().forEach(track => track.stop());
    });

    // Initialize page
    async function initialize() {
      updateStatus('Checking browser support...');
      if (!checkBrowserSupport()) {
        updateStatus('Browser does not support camera access');
        return;
      }

      if (typeof faceapi === 'undefined') {
        updateStatus('Face-api.js failed to load');
        return;
      }

      const modelResult = await loadModels();
      if (modelResult === true) {
        updateStatus('Face detection ready. Click "Start Camera"');
      } else if (modelResult === 'native') {
        const nativeReady = await initNativeFaceDetection();
        if (nativeReady) updateStatus('Native face detection ready. Click "Start Camera"');
        else updateStatus('Motion detection ready. Click "Start Camera"');
      } else {
        updateStatus('Motion detection ready. Click "Start Camera"');
      }

      startBtn.disabled = false;
    }

    window.addEventListener('load', initialize);
  </script>
</body>
</html>
