<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>wer bist du</title>
  <style>
    body { 
      display: flex; 
      flex-direction: column; 
      align-items: center; 
      font-family: sans-serif; 
      margin: 0;
      padding: 20px;
    }
    video { 
      border: 2px solid #333; 
      border-radius: 12px; 
      margin-top: 20px;
      max-width: 100%;
      height: auto;
    }
    #debug {
      margin-top: 10px;
      padding: 10px;
      border-radius: 5px;
      background-color: #e8f4f8;
      font-family: monospace;
      font-size: 12px;
      max-width: 600px;
      word-break: break-all;
      max-height: 200px;
      overflow-y: auto;
    }
    button {
      margin: 10px;
      padding: 10px 20px;
      font-size: 16px;
      border: none;
      border-radius: 5px;
      background-color: #007bff;
      color: white;
      cursor: pointer;
    }
    button:hover {
      background-color: #0056b3;
    }
    button:disabled {
      background-color: #ccc;
      cursor: not-allowed;
    }
    .toast {
      visibility: hidden;
      min-width: 300px;
      color: white;
      text-align: center;
      border-radius: 8px;
      padding: 16px;
      position: fixed;
      bottom: 30px;
      left: 50%;
      transform: translateX(-50%);
      z-index: 1;
      transition: visibility 0.5s, opacity 0.5s;
      opacity: 0;
    }
    .toast.show {
      visibility: visible;
      opacity: 1;
    }
    #faceToast { background-color: #f44336; }
    #lowLightToast { background-color: #ffa500; }
    #snrToast { background-color: #6a0dad; }
  </style>
</head>
<body>
  <h1>wer bist du</h1>
  <h3>v2.001</h3>
  <div id="debug"></div>
  <button id="startBtn" disabled>Start Camera</button>
  <video id="video" width="640" height="480" autoplay muted playsinline></video>

  <div id="faceToast" class="toast">‚ö†Ô∏è Another person detected in the background!</div>
  <div id="lowLightToast" class="toast">‚ö†Ô∏è Low lighting detected!</div>
  <div id="snrToast" class="toast">üé§ Background noise too high (low SNR)!</div>

  <!-- Face API CDN -->
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.13/dist/face-api.min.js"></script>

  <script>
    const video = document.getElementById('video');
    const startBtn = document.getElementById('startBtn');
    const debug = document.getElementById('debug');
    const faceToast = document.getElementById('faceToast');
    const lowLightToast = document.getElementById('lowLightToast');
    const snrToast = document.getElementById('snrToast');
    let detectionInterval;
    let faceLogInterval;
    let nativeFaceDetector = null;
    let lastFrame = null;
    let maxFacesInPeriod = 0;

    // Debug logging
    function addDebug(msg) {
      const timestamp = new Date().toLocaleTimeString();
      debug.innerHTML += `[${timestamp}] ${msg}<br>`;
      debug.scrollTop = debug.scrollHeight;
      console.log(msg);
    }

    function checkBrowserSupport() {
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        addDebug('ERROR: Camera API not supported');
        return false;
      }
      addDebug('‚úì Camera API supported');
      return true;
    }

    async function loadModels() {
      addDebug('Loading face detection models...');
      try {
        const modelPath = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1.7.13/model/';
        const loadPromise = Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri(modelPath),
          faceapi.nets.faceLandmark68Net.loadFromUri(modelPath),
          faceapi.nets.faceRecognitionNet.loadFromUri(modelPath)
        ]);
        const timeoutPromise = new Promise((_, reject) => setTimeout(() => reject(new Error('Model loading timeout')), 15000));
        await Promise.race([loadPromise, timeoutPromise]);
        addDebug('‚úì Models loaded');
        return true;
      } catch (err) {
        addDebug(`Model load failed: ${err.message}`);
        if ('FaceDetector' in window) {
          addDebug('Using native FaceDetector fallback');
          return 'native';
        }
        addDebug('Using motion detection fallback');
        return 'motion';
      }
    }

    async function initNativeFaceDetection() {
      try {
        nativeFaceDetector = new FaceDetector({ maxDetectedFaces: 10, fastMode: false });
        return true;
      } catch (err) {
        addDebug(`Native detector failed: ${err.message}`);
        return false;
      }
    }

    function isLowLight(video, threshold = 50) {
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const frame = ctx.getImageData(0, 0, canvas.width, canvas.height);
      let total = 0;
      for (let i = 0; i < frame.data.length; i += 4) {
        const brightness = 0.299*frame.data[i] + 0.587*frame.data[i+1] + 0.114*frame.data[i+2];
        total += brightness;
      }
      const avg = total / (canvas.width * canvas.height);
      if (Math.random() < 0.2) addDebug(`Brightness level: ${avg.toFixed(1)} (threshold: ${threshold})`);
      return avg < threshold;
    }

    function showToast(toast) {
      toast.className = "toast show";
      setTimeout(() => { toast.className = toast.className.replace("show", ""); }, 3000);
    }

    function detectMotion(video) {
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0);
      const currentFrame = ctx.getImageData(0, 0, canvas.width, canvas.height);
      let hasMotion = false;
      if (lastFrame) {
        let diff = 0;
        for (let i = 0; i < currentFrame.data.length; i += 4) {
          const r = Math.abs(currentFrame.data[i] - lastFrame.data[i]);
          const g = Math.abs(currentFrame.data[i+1] - lastFrame.data[i+1]);
          const b = Math.abs(currentFrame.data[i+2] - lastFrame.data[i+2]);
          diff += (r+g+b)/3;
        }
        const avgDiff = diff / (canvas.width * canvas.height);
        hasMotion = avgDiff > 10;
      }
      lastFrame = currentFrame;
      return hasMotion;
    }

    async function runDetection() {
      if (video.videoWidth === 0 || video.videoHeight === 0) return;
      let faceCount = 0;

      if (typeof faceapi !== 'undefined' && faceapi.nets.tinyFaceDetector.isLoaded) {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
        faceCount = detections.length;
      } else if (nativeFaceDetector) {
        const faces = await nativeFaceDetector.detect(video);
        faceCount = faces.length;
      } else {
        const hasMotion = detectMotion(video);
        faceCount = hasMotion ? 2 : 1;
      }

      // Track max faces in current 5-second period
      if (faceCount > maxFacesInPeriod) {
        maxFacesInPeriod = faceCount;
      }

      if (faceCount > 1) showToast(faceToast);

      const lowLight = isLowLight(video);
      if (lowLight) {
        addDebug('‚ö†Ô∏è Low lighting detected!');
        showToast(lowLightToast);
      }
    }

    // Log max faces every 5 seconds
    function logMaxFaces() {
      addDebug(`Max faces detected in last 5 seconds: ${maxFacesInPeriod}`);
      maxFacesInPeriod = 0; // Reset for next period
    }

    async function startVideo() {
      addDebug('Requesting camera access...');
      startBtn.disabled = true;
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 }, audio: false });
        video.srcObject = stream;
        addDebug('Camera connected. Starting detection...');
        // Start audio SNR too
        startAudioSNRLogging();
      } catch (err) {
        addDebug(`Camera error: ${err.message}`);
        startBtn.disabled = false;
      }
    }

    // --- AUDIO SNR LOGGING ---
    async function startAudioSNRLogging() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const audioCtx = new AudioContext();
        const source = audioCtx.createMediaStreamSource(stream);

        const analyser = audioCtx.createAnalyser();
        analyser.fftSize = 2048;
        source.connect(analyser);

        const dataArray = new Float32Array(analyser.fftSize);

        function computeSNR() {
          analyser.getFloatTimeDomainData(dataArray);

          let signalPower = 0;
          for (let i = 0; i < dataArray.length; i++) {
            signalPower += dataArray[i] * dataArray[i];
          }
          signalPower /= dataArray.length;

          const sorted = [...dataArray].map(Math.abs).sort((a, b) => a - b);
          const noiseSlice = sorted.slice(0, Math.floor(sorted.length * 0.1));
          let noisePower = noiseSlice.reduce((sum, v) => sum + v * v, 0) / noiseSlice.length;
          if (noisePower <= 0) noisePower = 1e-10;

          const snrDb = 10 * Math.log10(signalPower / noisePower);
          addDebug(`Audio SNR: ${snrDb.toFixed(2)} dB`);

          if (snrDb < 10) {
            showToast(snrToast);
          }
        }

        setInterval(computeSNR, 1000);
        addDebug("‚úì Audio SNR logging started");
      } catch (err) {
        addDebug("Audio error: " + err.message);
      }
    }

    startBtn.addEventListener('click', startVideo);
    video.addEventListener('play', () => {
      if (detectionInterval) clearInterval(detectionInterval);
      if (faceLogInterval) clearInterval(faceLogInterval);
      
      detectionInterval = setInterval(runDetection, 1000);
      faceLogInterval = setInterval(logMaxFaces, 5000);
      
      addDebug('Video started. Detection active.');
    });

    window.addEventListener('beforeunload', () => {
      if (detectionInterval) clearInterval(detectionInterval);
      if (faceLogInterval) clearInterval(faceLogInterval);
      if (video.srcObject) video.srcObject.getTracks().forEach(track => track.stop());
    });

    async function initialize() {
      addDebug('Checking browser support...');
      if (!checkBrowserSupport()) {
        addDebug('Browser does not support camera access');
        return;
      }
      if (typeof faceapi === 'undefined') {
        addDebug('Face-api.js failed to load');
        return;
      }
      const modelResult = await loadModels();
      if (modelResult === 'native') {
        await initNativeFaceDetection();
      }
      startBtn.disabled = false;
    }

    window.addEventListener('load', initialize);
  </script>
</body>
</html>
